{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass LanguageDataset(Dataset):\\n    def __init__(self, max_length, num_samples, p, device=\\'cpu\\'):\\n        Generate a language dataset.\\n\\n        Args:\\n            max_length: Maximum length of the sequence\\n            num_samples: Number of samples to generate\\n            p: Probability of a sample being from the language\\n            device: Device to store the data (\\'cpu\\' or \\'cuda\\')\\n        \"\\n        super().__init__()\\n        self.max_length = max_length\\n        self.num_samples = num_samples\\n        self.p = p\\n        self.device = device\\n        self.generate_data()\\n\\n    def generate_data(self):\\n        data = []\\n        labels = []\\n        \\n        while len(data) < self.num_samples:\\n            n = np.random.randint(1, min((self.max_length + 2) // 3, 8))\\n            total_length = 3 * n\\n            if total_length > self.max_length:\\n                continue\\n\\n            if np.random.rand() < self.p:\\n                sample = \\'a\\' * n + \\'b\\' * n + \\'c\\' * n\\n                data.append([ord(c) for c in sample])  # Convert chars to ASCII values\\n                labels.append(1)\\n            else:\\n                sample = \\'\\'.join(np.random.choice([\\'a\\', \\'b\\', \\'c\\'], total_length))\\n                data.append([ord(c) for c in sample])  # Convert chars to ASCII values\\n                labels.append(0)\\n\\n        self.data = torch.tensor(data, dtype=torch.float32).to(self.device)\\n        self.labels = torch.tensor(labels, dtype=torch.long).to(self.device)\\n\\n    def __len__(self):\\n        return self.num_samples\\n\\n    def __getitem__(self, idx):\\n        data_point = self.data[idx]\\n        data_label = self.labels[idx]\\n        return data_point, data_label\\n\\n    def toNumpy(self):\\n        return self.data.cpu().numpy(), self.labels.cpu().numpy()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, max_length, num_samples, p, device='cpu'):\n",
    "        \"\"\"\"\"\"Generate a language dataset.\n",
    "\n",
    "        Args:\n",
    "            max_length: Maximum length of the sequence\n",
    "            num_samples: Number of samples to generate\n",
    "            p: Probability of a sample being from the language\n",
    "            device: Device to store the data ('cpu' or 'cuda')\n",
    "        \"\"\"\"\"\"\"\n",
    "        super().__init__()\n",
    "        self.max_length = max_length\n",
    "        self.num_samples = num_samples\n",
    "        self.p = p\n",
    "        self.device = device\n",
    "        self.generate_data()\n",
    "\n",
    "    def generate_data(self):\n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        while len(data) < self.num_samples:\n",
    "            n = np.random.randint(1, min((self.max_length + 2) // 3, 8))\n",
    "            total_length = 3 * n\n",
    "            if total_length > self.max_length:\n",
    "                continue\n",
    "\n",
    "            if np.random.rand() < self.p:\n",
    "                sample = 'a' * n + 'b' * n + 'c' * n\n",
    "                data.append([ord(c) for c in sample])  # Convert chars to ASCII values\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                sample = ''.join(np.random.choice(['a', 'b', 'c'], total_length))\n",
    "                data.append([ord(c) for c in sample])  # Convert chars to ASCII values\n",
    "                labels.append(0)\n",
    "\n",
    "        self.data = torch.tensor(data, dtype=torch.float32).to(self.device)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long).to(self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.labels[idx]\n",
    "        return data_point, data_label\n",
    "\n",
    "    def toNumpy(self):\n",
    "        return self.data.cpu().numpy(), self.labels.cpu().numpy()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try this with padded sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, max_length, num_samples, p, device='cpu'):\n",
    "        \"\"\"Generate a language dataset.\n",
    "\n",
    "        Args:\n",
    "            max_length: Maximum length of the sequence\n",
    "            num_samples: Number of samples to generate\n",
    "            p: Probability of a sample being from the language\n",
    "            device: Device to store the data ('cpu' or 'cuda')\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_length = max_length\n",
    "        self.num_samples = num_samples\n",
    "        self.p = p\n",
    "        self.device = device\n",
    "        self.generate_data()\n",
    "\n",
    "    def generate_data(self):\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        while len(data) < self.num_samples:\n",
    "            n = np.random.randint(1, min((self.max_length + 2) // 3, 8))\n",
    "            total_length = 3 * n\n",
    "            if total_length > self.max_length:\n",
    "                continue\n",
    "\n",
    "            if np.random.rand() < self.p:\n",
    "                sample = 'a' * n + 'b' * n + 'c' * n\n",
    "                #data.append([ord(c) for c in sample])  # Convert chars to ASCII values\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                sample = ''.join(np.random.choice(['a', 'b', 'c'], total_length))\n",
    "                #data.append([ord(c) for c in sample])  # Convert chars to ASCII values\n",
    "                labels.append(0)\n",
    "\n",
    "        # Pad sequences to ensure consistent dimensions\n",
    "        padded_data = self.pad_sequences(data, self.max_length)\n",
    "\n",
    "        self.data = torch.tensor(padded_data, dtype=torch.float32).to(self.device)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long).to(self.device)\n",
    "\n",
    "    def pad_sequences(self, sequences, max_length):\n",
    "        padded_sequences = np.zeros((len(sequences), max_length))\n",
    "        for i, seq in enumerate(sequences):\n",
    "            padded_sequences[i, :len(seq)] = seq\n",
    "        return padded_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.labels[idx]\n",
    "        return data_point, data_label\n",
    "\n",
    "    def toNumpy(self):\n",
    "        return self.data.cpu().numpy(), self.labels.cpu().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "dataset = LanguageDataset(max_length=20, num_samples=100, p=0.5, device='cpu')\n",
    "print(len(dataset))\n",
    "print(dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5752aa9ab330d3759c83a1b34e6976ab41b98e9e7a9be5fc074dbcab196bea16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
